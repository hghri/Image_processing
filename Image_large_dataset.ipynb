{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1aGjI8Xk4hyAjsOpnbI1EnvQ6cdeYQl_e",
      "authorship_tag": "ABX9TyNPSeXy8PahJ9UioXmevH+8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hghri/Image_processing/blob/main/Image_large_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OFj79GwA5NLQ"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import zipfile"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "import PIL"
      ],
      "metadata": {
        "id": "suj4s3FVWdAz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "respond=requests.get('https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip')"
      ],
      "metadata": {
        "id": "cBJF5yxL6CtR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open ('catvsdog.zip','wb') as file:\n",
        "  file.write(respond.content)"
      ],
      "metadata": {
        "id": "Fv6HW_5B6lZs"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with zipfile.ZipFile('/content/catvsdog.zip','r') as zip_ref:\n",
        "  zip_ref.extractall(\"./extracted_folder\")"
      ],
      "metadata": {
        "id": "c8FOes_569wM"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D,Dense,MaxPool2D,Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "cX0nit7L7vNy"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "image_dir = \"/content/extracted_folder/PetImages/Cat\"\n",
        "\n",
        "for filename in os.listdir(image_dir):\n",
        "    try:\n",
        "        image_path = os.path.join(image_dir, filename)\n",
        "        img = Image.open(image_path)\n",
        "        # Process the image\n",
        "    except PIL.UnidentifiedImageError:\n",
        "        print(f\"Skipping {filename}: UnidentifiedImageError\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {filename}: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_R6u0ojWTnK",
        "outputId": "c9884a86-907d-447a-cad6-32abb5ea614e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping 666.jpg: UnidentifiedImageError\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.remove('/content/extracted_folder/PetImages/Dog/Thumbs.db')"
      ],
      "metadata": {
        "id": "4G6zXCY5Xc5s"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.remove('/content/extracted_folder/PetImages/Cat/666.jpg')"
      ],
      "metadata": {
        "id": "Zt826yxCXJS7"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.remove('/content/extracted_folder/PetImages/Cat/Thumbs.db')"
      ],
      "metadata": {
        "id": "nq3KJIpvXXHc"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.remove('/content/extracted_folder/PetImages/Dog/11702.jpg')"
      ],
      "metadata": {
        "id": "eBstYP7cXhoi"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "\n",
        "def move_random_files(source_folder, destination_folder, num_files):\n",
        "    files = os.listdir(source_folder)\n",
        "    random_files = random.sample(files, num_files)\n",
        "    for file_name in random_files:\n",
        "        source_file_path = os.path.join(source_folder, file_name)\n",
        "        destination_file_path = os.path.join(destination_folder, file_name)\n",
        "        shutil.move(source_file_path, destination_file_path)\n",
        "\n",
        "\n",
        "source_folder = \"/content/extracted_folder/PetImages/Cat\"\n",
        "destination_folder = \"/content/PetTest/Cat\"\n",
        "num_files_to_move = 2500\n",
        "move_random_files(source_folder, destination_folder, num_files_to_move)\n"
      ],
      "metadata": {
        "id": "eKYf9O5Z-UiC"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "\n",
        "def move_random_files(source_folder, destination_folder, num_files):\n",
        "    files = os.listdir(source_folder)\n",
        "    random_files = random.sample(files, num_files)\n",
        "    for file_name in random_files:\n",
        "        source_file_path = os.path.join(source_folder, file_name)\n",
        "        destination_file_path = os.path.join(destination_folder, file_name)\n",
        "        shutil.move(source_file_path, destination_file_path)\n",
        "\n",
        "\n",
        "source_folder = \"/content/extracted_folder/PetImages/Dog\"\n",
        "destination_folder = \"/content/PetTest/Dog\"\n",
        "num_files_to_move = 2500\n",
        "move_random_files(source_folder, destination_folder, num_files_to_move)\n"
      ],
      "metadata": {
        "id": "ghneVRvB-wDY"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen=ImageDataGenerator(rescale=1.0/255\n",
        "                            ,zoom_range=0.4\n",
        "                            ,horizontal_flip=True\n",
        "                            ,vertical_flip=True\n",
        "                            ,rotation_range=50\n",
        "                            ,width_shift_range=0.3\n",
        "                            ,height_shift_range=0.3\n",
        "                            ,shear_range=0.4\n",
        "                            ,fill_mode='nearest',\n",
        "                            validation_split=0.3)\n"
      ],
      "metadata": {
        "id": "oVEorlVh8lAC"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_datagen=ImageDataGenerator(rescale=1.0/255\n",
        "                            ,zoom_range=0.4\n",
        "                            ,horizontal_flip=True\n",
        "                            ,vertical_flip=True\n",
        "                            ,rotation_range=50\n",
        "                            ,width_shift_range=0.3\n",
        "                            ,height_shift_range=0.3\n",
        "                            ,shear_range=0.4\n",
        "                            ,fill_mode='nearest',\n",
        "                            validation_split=0.3)\n"
      ],
      "metadata": {
        "id": "khf7RzJpfpyw"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "    '/content/extracted_folder/PetImages/',\n",
        "    target_size=(250, 250),\n",
        "    batch_size=50,\n",
        "    class_mode='binary',\n",
        "    subset='training'  # Specify subset for training data\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZM9sFXHfxw8",
        "outputId": "bc3b9b87-e9af-4cbc-c956-3ddc712f9b76"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 17500 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_generator = test_datagen.flow_from_directory(\n",
        "   '/content/extracted_folder/PetImages/',\n",
        "    target_size=(250, 250),\n",
        "    batch_size=50,\n",
        "    class_mode='binary',\n",
        "    subset='validation'  # Specify subset for validation data\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmyCG1kZf6cn",
        "outputId": "1ef5baa2-7a5d-4c3b-9ea4-8598776ab6f4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 7498 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train=data_gen.flow_from_directory('/content/extracted_folder/PetImages/',class_mode='binary',batch_size=50,target_size=(250, 250))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlGKxiTWc5t7",
        "outputId": "53c77dcb-82dc-405e-da23-32a9623c4284"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 19998 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test=data_gen.flow_from_directory('/content/PetTest/',class_mode='binary',batch_size=50,target_size=(250, 250))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1-7T-4E-7mM",
        "outputId": "25cfad29-2189-46d3-f1a9-75c56ee8847e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5000 images belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential()\n",
        "model.add(Conv2D(64,(3,3),activation='relu',padding='same',input_shape=(250,250,3)))\n",
        "model.add(MaxPool2D((2,2)))\n",
        "model.add(Conv2D(128,(3,3),activation='relu',padding='same'))\n",
        "model.add(MaxPool2D((2,2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense (400,activation='relu'))\n",
        "model.add(Dense (1,activation='sigmoid'))\n"
      ],
      "metadata": {
        "id": "5UCgCeZ5_F2q"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9T-Antw0Akb7",
        "outputId": "abe7c336-030a-46ee-acc4-427af5512e31"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 250, 250, 64)      1792      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 125, 125, 64)      0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 125, 125, 128)     73856     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 62, 62, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 492032)            0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 400)               196813200 \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 401       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 196889249 (751.07 MB)\n",
            "Trainable params: 196889249 (751.07 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=Adam(),loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "dd8nJQ0RApZy"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-srhQtc_BxKk",
        "outputId": "6c72025e-88ec-4a28-e4cd-49475238f42f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.preprocessing.image.DirectoryIterator at 0x7fc020fcec80>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hitory=model.fit_generator(train_generator,steps_per_epoch=len(train_generator),validation_data=test_generator,validation_steps=len(test_generator),epochs=15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DG3LOqj5BN00",
        "outputId": "68ee95f3-26c0-42b2-a40a-8f6be2143c5c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-20-12180e7541f0>:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  hitory=model.fit_generator(train_generator,steps_per_epoch=len(train_generator),validation_data=test_generator,validation_steps=len(test_generator),epochs=15)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "221/350 [=================>............] - ETA: 1:53 - loss: 1.2517 - accuracy: 0.5318"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/TiffImagePlugin.py:858: UserWarning: Truncated File Read\n",
            "  warnings.warn(str(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "350/350 [==============================] - 448s 1s/step - loss: 1.0442 - accuracy: 0.5401 - val_loss: 0.6850 - val_accuracy: 0.5628\n",
            "Epoch 2/15\n",
            "350/350 [==============================] - 433s 1s/step - loss: 0.6848 - accuracy: 0.5587 - val_loss: 0.6856 - val_accuracy: 0.5684\n",
            "Epoch 3/15\n",
            "350/350 [==============================] - 430s 1s/step - loss: 0.6876 - accuracy: 0.5649 - val_loss: 0.6786 - val_accuracy: 0.5750\n",
            "Epoch 4/15\n",
            "350/350 [==============================] - 429s 1s/step - loss: 0.6729 - accuracy: 0.5861 - val_loss: 0.6659 - val_accuracy: 0.6054\n",
            "Epoch 5/15\n",
            "350/350 [==============================] - 453s 1s/step - loss: 0.6560 - accuracy: 0.6119 - val_loss: 0.6363 - val_accuracy: 0.6276\n",
            "Epoch 6/15\n",
            "350/350 [==============================] - 433s 1s/step - loss: 0.6423 - accuracy: 0.6284 - val_loss: 0.6233 - val_accuracy: 0.6483\n",
            "Epoch 7/15\n",
            "350/350 [==============================] - 428s 1s/step - loss: 0.6285 - accuracy: 0.6454 - val_loss: 0.6087 - val_accuracy: 0.6570\n",
            "Epoch 8/15\n",
            "350/350 [==============================] - 425s 1s/step - loss: 0.6164 - accuracy: 0.6562 - val_loss: 0.5885 - val_accuracy: 0.6830\n",
            "Epoch 9/15\n",
            "350/350 [==============================] - 425s 1s/step - loss: 0.6039 - accuracy: 0.6677 - val_loss: 0.5937 - val_accuracy: 0.6767\n",
            "Epoch 10/15\n",
            "350/350 [==============================] - 422s 1s/step - loss: 0.5930 - accuracy: 0.6768 - val_loss: 0.5735 - val_accuracy: 0.6923\n",
            "Epoch 11/15\n",
            "350/350 [==============================] - 423s 1s/step - loss: 0.5799 - accuracy: 0.6918 - val_loss: 0.5670 - val_accuracy: 0.7018\n",
            "Epoch 12/15\n",
            "350/350 [==============================] - 422s 1s/step - loss: 0.5732 - accuracy: 0.6942 - val_loss: 0.5517 - val_accuracy: 0.7137\n",
            "Epoch 13/15\n",
            "350/350 [==============================] - 421s 1s/step - loss: 0.5704 - accuracy: 0.6991 - val_loss: 0.5552 - val_accuracy: 0.7071\n",
            "Epoch 14/15\n",
            "350/350 [==============================] - 421s 1s/step - loss: 0.5587 - accuracy: 0.7063 - val_loss: 0.5641 - val_accuracy: 0.7098\n",
            "Epoch 15/15\n",
            "350/350 [==============================] - 422s 1s/step - loss: 0.5529 - accuracy: 0.7134 - val_loss: 0.5370 - val_accuracy: 0.7282\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights('catvsdog.h5')"
      ],
      "metadata": {
        "id": "tYIWXBtc7lZn"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ia3JiKIf6CVg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}